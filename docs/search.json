[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 normtest authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/multi_group_vignette.html","id":"standard-workflow","dir":"Articles","previous_headings":"","what":"Standard Workflow","title":"multi_group_vignette","text":"follows vignette standard workflow using normtest package analyze data two groups. possible input raw data, recommended use preprocessed, normalized, cleaned data. goal take dataset experiment multiple factors analyze using appropriate statistics. start loading data. .csv file normalized gene counts, called multigroup_counts.csv. Note data already cleaned ready analysis. , however, need change column “X” rownames data, remove column. use cf() function included normtest package. simple helper function set specified column (defaults column 1) rownames, remove column data. Now must build sample_info object. purpose object define groups factors sample data belongs . sample experiement given one two diets, d1 d2. sample also given treatment, either t1 t2. therefore constructed groups, define diet treatment sample. groups variable must linear combination two variables (case, diet treatment). words, group variable must describe distribution two variables. group-d1t1 describes samples got diet1 treatment1, group-d2t1 describes samples got diet2 treatment1, etc. reason multicomparison tests used analysis able consider two factors, rather one. statistical criteria used sort data one three tiers relies group distributions defined first two variables. order criteria remain satisfied performing multicomparison tests, group variable must follow convention. sample_info table example . non-example (.e., don’t ). Notice group variables “line ” “describe” distribution diet treatment variables. Now sample_info object counts ready, can run analysis. can use main function “rui” call appropriate functions succession. write three .csv files current directory, “anova_results.csv”, “multi_group_welch_results.csv”, “KW_results.csv”. also assign three variables tier1, tier2, tier3 global r environment. important variables names, please note function overwrite . Also note depending size data, function take several minutes run. , rest , demonstrate next steps useful purposes. Let’s look anova_results. file contains data every comparison, unwieldy consider every comparison . ’ll trim make easier. Now x1 shows pvalues first two experiemental factors interaction. Suppose interested interaction, wish see pvalues significant alpha = 0.05 level. now use rows significant interaction index whole anova_results table get info comparisons. Lets consider another use case. ’ll use KW_results file time. Suppose interested looking comparison d1t1_vs_d2t2. ’ll get just columns kw table. , maybe want see fold changes largest (considering absoulute values). Certainly, negative infinity sounds like large fold change. actually likely result us taking log2(0). probably descriptive remove infinite values comparison. Now values useful us. use cases , specific use cases. much can data processing, likely dependent kind data course, ’re trying achieve.","code":"counts <- read.csv(\"multigroup_counts.csv\") head(counts) #>                    X          A1          A2         A3         A4         A5 #> 1 ENSMUSG00000025902   42.596358   36.920507   48.78769   25.70264   58.18297 #> 2 ENSMUSG00000033845 1459.172931 1982.848408 2104.29023 1232.21473 1657.53818 #> 3 ENSMUSG00000102275    3.962452    2.171795    3.85166    0.00000   14.88402 #> 4 ENSMUSG00000025903 3560.263079 3774.578897 3823.41446 2246.71300 3120.23106 #> 5 ENSMUSG00000033813 2185.292251 2754.921364 2381.60975 1079.51082  898.45335 #> 6 ENSMUSG00000033793 1659.276755 1602.784365 1096.43920 1791.62510 1539.81914 #>            B1          B2          B3          B4         B5         C1 #> 1   24.714052    9.690969   35.653631   10.575432  131.70564   53.27348 #> 2 1004.553532 1253.769099 1786.643080 1586.314853  957.06099 1075.78061 #> 3    1.453768    4.845484    6.602524    6.169002   24.14603   48.11798 #> 4 1814.302182 1755.276738 4988.867373 2218.196936 1391.68960 2845.83496 #> 5 1626.766139 2500.269970 2666.099319 1662.986737  628.89443 1115.30609 #> 6 1155.018496 2048.428547 1853.988828 1631.260440 1334.61716 1814.73534 #>           C2         C3         C4         C5          D1         D2 #> 1   81.27266   99.66504   44.17841   49.13275   64.340583   46.89579 #> 2 1963.54755  924.16674 2186.20028 1422.61645  646.980310  474.87678 #> 3   30.88361    8.23678   40.39169   20.09976    4.170223    4.09769 #> 4 8073.62639 1966.11943 6681.03814 1932.92706  853.108475  775.37407 #> 5 1666.08960  743.78125 1348.07269  768.25755  987.747103 1069.95247 #> 6 3403.69915  717.42355 2890.53039 1218.26887 1481.620654 1322.18808 #>            D3          D4         D5 #> 1   21.392093   32.662957  126.06043 #> 2 1175.772816 1003.705461  500.01961 #> 3    7.130698    5.443826    1.20632 #> 4 1571.130387 1116.664855 1567.00957 #> 5  873.906615 1108.499115  979.53177 #> 6 1197.957209 1184.032204 1220.19260 counts <- cf(counts) head(counts) #>                             A1          A2         A3         A4         A5 #> ENSMUSG00000025902   42.596358   36.920507   48.78769   25.70264   58.18297 #> ENSMUSG00000033845 1459.172931 1982.848408 2104.29023 1232.21473 1657.53818 #> ENSMUSG00000102275    3.962452    2.171795    3.85166    0.00000   14.88402 #> ENSMUSG00000025903 3560.263079 3774.578897 3823.41446 2246.71300 3120.23106 #> ENSMUSG00000033813 2185.292251 2754.921364 2381.60975 1079.51082  898.45335 #> ENSMUSG00000033793 1659.276755 1602.784365 1096.43920 1791.62510 1539.81914 #>                             B1          B2          B3          B4         B5 #> ENSMUSG00000025902   24.714052    9.690969   35.653631   10.575432  131.70564 #> ENSMUSG00000033845 1004.553532 1253.769099 1786.643080 1586.314853  957.06099 #> ENSMUSG00000102275    1.453768    4.845484    6.602524    6.169002   24.14603 #> ENSMUSG00000025903 1814.302182 1755.276738 4988.867373 2218.196936 1391.68960 #> ENSMUSG00000033813 1626.766139 2500.269970 2666.099319 1662.986737  628.89443 #> ENSMUSG00000033793 1155.018496 2048.428547 1853.988828 1631.260440 1334.61716 #>                            C1         C2         C3         C4         C5 #> ENSMUSG00000025902   53.27348   81.27266   99.66504   44.17841   49.13275 #> ENSMUSG00000033845 1075.78061 1963.54755  924.16674 2186.20028 1422.61645 #> ENSMUSG00000102275   48.11798   30.88361    8.23678   40.39169   20.09976 #> ENSMUSG00000025903 2845.83496 8073.62639 1966.11943 6681.03814 1932.92706 #> ENSMUSG00000033813 1115.30609 1666.08960  743.78125 1348.07269  768.25755 #> ENSMUSG00000033793 1814.73534 3403.69915  717.42355 2890.53039 1218.26887 #>                             D1         D2          D3          D4         D5 #> ENSMUSG00000025902   64.340583   46.89579   21.392093   32.662957  126.06043 #> ENSMUSG00000033845  646.980310  474.87678 1175.772816 1003.705461  500.01961 #> ENSMUSG00000102275    4.170223    4.09769    7.130698    5.443826    1.20632 #> ENSMUSG00000025903  853.108475  775.37407 1571.130387 1116.664855 1567.00957 #> ENSMUSG00000033813  987.747103 1069.95247  873.906615 1108.499115  979.53177 #> ENSMUSG00000033793 1481.620654 1322.18808 1197.957209 1184.032204 1220.19260 sample_info <- data.frame(samples = colnames(counts),                            diet = c(rep(\"d1\", 10), rep(\"d2\", 10)),                            treatment = c(rep(\"t1\", 5), rep(\"t2\", 5), rep(\"t1\", 5), rep(\"t2\", 5)),                           group = c(rep(\"d1t1\", 5), rep(\"d1t2\", 5), rep(\"d2t1\", 5), rep(\"d2t2\", 5))) sample_info #>    samples diet treatment group #> 1       A1   d1        t1  d1t1 #> 2       A2   d1        t1  d1t1 #> 3       A3   d1        t1  d1t1 #> 4       A4   d1        t1  d1t1 #> 5       A5   d1        t1  d1t1 #> 6       B1   d1        t2  d1t2 #> 7       B2   d1        t2  d1t2 #> 8       B3   d1        t2  d1t2 #> 9       B4   d1        t2  d1t2 #> 10      B5   d1        t2  d1t2 #> 11      C1   d2        t1  d2t1 #> 12      C2   d2        t1  d2t1 #> 13      C3   d2        t1  d2t1 #> 14      C4   d2        t1  d2t1 #> 15      C5   d2        t1  d2t1 #> 16      D1   d2        t2  d2t2 #> 17      D2   d2        t2  d2t2 #> 18      D3   d2        t2  d2t2 #> 19      D4   d2        t2  d2t2 #> 20      D5   d2        t2  d2t2 #dont do this!!! this is bad!!! bad_sample_info <- data.frame(samples = colnames(counts),                            diet = c(rep(\"d1\", 10), rep(\"d2\", 10)),                            treatment = c(rep(\"t1\", 5), rep(\"t2\", 5), rep(\"t1\", 5), rep(\"t2\", 5)),                           group = c(rep(\"group1\", 2), rep(\"group2\", 8), rep(\"group3\", 3), rep(\"group4\", 7))) #dont use this!!!  bad_sample_info #>    samples diet treatment  group #> 1       A1   d1        t1 group1 #> 2       A2   d1        t1 group1 #> 3       A3   d1        t1 group2 #> 4       A4   d1        t1 group2 #> 5       A5   d1        t1 group2 #> 6       B1   d1        t2 group2 #> 7       B2   d1        t2 group2 #> 8       B3   d1        t2 group2 #> 9       B4   d1        t2 group2 #> 10      B5   d1        t2 group2 #> 11      C1   d2        t1 group3 #> 12      C2   d2        t1 group3 #> 13      C3   d2        t1 group3 #> 14      C4   d2        t1 group4 #> 15      C5   d2        t1 group4 #> 16      D1   d2        t2 group4 #> 17      D2   d2        t2 group4 #> 18      D3   d2        t2 group4 #> 19      D4   d2        t2 group4 #> 20      D5   d2        t2 group4 rui(counts, sample_info$diet, sample_info$treatment, sample_info$group) x <- read.csv(\"anova_results.csv\") x <- cf(x) head(x) #>                    sample_info.diet sample_info.treatment interaction #> ENSMUSG00000033845       0.06171619           0.006996183 0.305605405 #> ENSMUSG00000102275       0.03086615           0.023743674 0.004044129 #> ENSMUSG00000025903       0.86172468           0.015858974 0.147887715 #> ENSMUSG00000033813       0.01243511           0.764306572 0.883878516 #> ENSMUSG00000025907       0.03025391           0.001000366 0.001239308 #> ENSMUSG00000103509       0.29460497           0.591632360 0.018691045 #>                    Pval_d1t2.d1t1 log2FoldChange_d1t1_vs_d1t2 Pval_d2t1.d1t1 #> ENSMUSG00000033845      0.4952819                  0.35665477    0.906048100 #> ENSMUSG00000102275      0.9293205                 -0.79719065    0.004678281 #> ENSMUSG00000025903      0.8384879                  0.44153626    0.778798364 #> ENSMUSG00000033813      0.9994928                  0.03370861    0.272506358 #> ENSMUSG00000025907      0.9998602                  0.02643423    0.002061744 #> ENSMUSG00000103509      0.4808942                  0.73634190    0.079239512 #>                    log2FoldChange_d1t1_vs_d2t1 Pval_d2t2.d1t1 #> ENSMUSG00000033845                   0.1558363      0.0113916 #> ENSMUSG00000102275                  -2.5704872      0.9997002 #> ENSMUSG00000025903                  -0.3796384      0.2174388 #> ENSMUSG00000033813                   0.7211171      0.1636236 #> ENSMUSG00000025907                  -1.0853386      0.6605803 #> ENSMUSG00000103509                   1.8099884      0.9807832 #>                    log2FoldChange_d1t1_vs_d2t2 Pval_d2t1.d1t2 #> ENSMUSG00000033845                   1.1500564    0.868594759 #> ENSMUSG00000102275                   0.1737047    0.015941073 #> ENSMUSG00000025903                   1.4899734    0.317149991 #> ENSMUSG00000033813                   0.8896147    0.320267321 #> ENSMUSG00000025907                   0.4982817    0.001782535 #> ENSMUSG00000103509                   0.1577352    0.663294460 #>                    log2FoldChange_d1t2_vs_d2t1 Pval_d2t2.d1t2 #> ENSMUSG00000033845                  -0.2008184      0.1742212 #> ENSMUSG00000102275                  -1.7732966      0.8967876 #> ENSMUSG00000025903                  -0.8211747      0.6353750 #> ENSMUSG00000033813                   0.6874085      0.1964249 #> ENSMUSG00000025907                  -1.1117728      0.7027777 #> ENSMUSG00000103509                   1.0736465      0.7038026 #>                    log2FoldChange_d1t2_vs_d2t2 Pval_d2t2.d2t1 #> ENSMUSG00000033845                   0.7934016   0.0433811737 #> ENSMUSG00000102275                   0.9708953   0.0038723213 #> ENSMUSG00000025903                   1.0484371   0.0395453133 #> ENSMUSG00000033813                   0.8559061   0.9881694153 #> ENSMUSG00000025907                   0.4718475   0.0002090351 #> ENSMUSG00000103509                  -0.5786067   0.1553188917 #>                    log2FoldChange_d2t1_vs_d2t2 #> ENSMUSG00000033845                   0.9942200 #> ENSMUSG00000102275                   2.7441919 #> ENSMUSG00000025903                   1.8696118 #> ENSMUSG00000033813                   0.1684976 #> ENSMUSG00000025907                   1.5836203 #> ENSMUSG00000103509                  -1.6522532 x1 <- x[, 1:3] head(x1) #>                    sample_info.diet sample_info.treatment interaction #> ENSMUSG00000033845       0.06171619           0.006996183 0.305605405 #> ENSMUSG00000102275       0.03086615           0.023743674 0.004044129 #> ENSMUSG00000025903       0.86172468           0.015858974 0.147887715 #> ENSMUSG00000033813       0.01243511           0.764306572 0.883878516 #> ENSMUSG00000025907       0.03025391           0.001000366 0.001239308 #> ENSMUSG00000103509       0.29460497           0.591632360 0.018691045 intx <- x1[x1[, 3] < 0.05, ] head(intx) #>                    sample_info.diet sample_info.treatment interaction #> ENSMUSG00000102275      0.030866152           0.023743674 0.004044129 #> ENSMUSG00000025907      0.030253909           0.001000366 0.001239308 #> ENSMUSG00000103509      0.294604969           0.591632360 0.018691045 #> ENSMUSG00000043760      0.425777210           0.038880813 0.007299374 #> ENSMUSG00000086240      0.155950292           0.002275057 0.001707565 #> ENSMUSG00000102336      0.005720923           0.001141471 0.030551998 intx_names <- rownames(intx) big_intx <- x[intx_names, ] head(big_intx) #>                    sample_info.diet sample_info.treatment interaction #> ENSMUSG00000102275      0.030866152           0.023743674 0.004044129 #> ENSMUSG00000025907      0.030253909           0.001000366 0.001239308 #> ENSMUSG00000103509      0.294604969           0.591632360 0.018691045 #> ENSMUSG00000043760      0.425777210           0.038880813 0.007299374 #> ENSMUSG00000086240      0.155950292           0.002275057 0.001707565 #> ENSMUSG00000102336      0.005720923           0.001141471 0.030551998 #>                    Pval_d1t2.d1t1 log2FoldChange_d1t1_vs_d1t2 Pval_d2t1.d1t1 #> ENSMUSG00000102275      0.9293205                 -0.79719065    0.004678281 #> ENSMUSG00000025907      0.9998602                  0.02643423    0.002061744 #> ENSMUSG00000103509      0.4808942                  0.73634190    0.079239512 #> ENSMUSG00000043760      0.9363238                  0.19599827    0.409290899 #> ENSMUSG00000086240      0.9996682                 -0.03751340    0.009200291 #> ENSMUSG00000102336      0.6846489                 -1.85106368    0.937630517 #>                    log2FoldChange_d1t1_vs_d2t1 Pval_d2t2.d1t1 #> ENSMUSG00000102275                  -2.5704872   0.9997001782 #> ENSMUSG00000025907                  -1.0853386   0.6605803067 #> ENSMUSG00000103509                   1.8099884   0.9807832201 #> ENSMUSG00000043760                   0.6181122   0.1742660356 #> ENSMUSG00000086240                  -1.0128465   0.4544361557 #> ENSMUSG00000102336                  -1.2303725   0.0006189718 #>                    log2FoldChange_d1t1_vs_d2t2 Pval_d2t1.d1t2 #> ENSMUSG00000102275                   0.1737047    0.015941073 #> ENSMUSG00000025907                   0.4982817    0.001782535 #> ENSMUSG00000103509                   0.1577352    0.663294460 #> ENSMUSG00000043760                  -0.5598348    0.744316191 #> ENSMUSG00000086240                   0.7714724    0.011180370 #> ENSMUSG00000102336                  -3.6765023    0.947807619 #>                    log2FoldChange_d1t2_vs_d2t1 Pval_d2t2.d1t2 #> ENSMUSG00000102275                  -1.7732966    0.896787585 #> ENSMUSG00000025907                  -1.1117728    0.702777713 #> ENSMUSG00000103509                   1.0736465    0.703802587 #> ENSMUSG00000043760                   0.4221139    0.061768005 #> ENSMUSG00000086240                  -0.9753331    0.402761498 #> ENSMUSG00000102336                   0.6206911    0.005887267 #>                    log2FoldChange_d1t2_vs_d2t2 Pval_d2t2.d2t1 #> ENSMUSG00000102275                   0.9708953   0.0038723213 #> ENSMUSG00000025907                   0.4718475   0.0002090351 #> ENSMUSG00000103509                  -0.5786067   0.1553188917 #> ENSMUSG00000043760                  -0.7558331   0.0082998718 #> ENSMUSG00000086240                   0.8089858   0.0004393651 #> ENSMUSG00000102336                  -1.8254386   0.0019635408 #>                    log2FoldChange_d2t1_vs_d2t2 #> ENSMUSG00000102275                    2.744192 #> ENSMUSG00000025907                    1.583620 #> ENSMUSG00000103509                   -1.652253 #> ENSMUSG00000043760                   -1.177947 #> ENSMUSG00000086240                    1.784319 #> ENSMUSG00000102336                   -2.446130 kw <- read.csv(\"KW_results.csv\") kw <- cf(kw) comp <- kw[, 6:7] head(comp) #>                    d1t1_vs_d2t2 log2FoldChange_d1t1_vs_d2t2 #> ENSMUSG00000025902    1.0000000                 -0.45740467 #> ENSMUSG00000090031    0.2534171                 -1.36499707 #> ENSMUSG00000051285    0.1292183                  1.49257918 #> ENSMUSG00000098234    1.0000000                 -0.03072924 #> ENSMUSG00000099032    1.0000000                 -0.17768959 #> ENSMUSG00000048960    0.2877529                 -1.59468579 ordered_comp <- comp[order(abs(comp[, 2]), decreasing = TRUE), ] head(ordered_comp) #>                    d1t1_vs_d2t2 log2FoldChange_d1t1_vs_d2t2 #> ENSMUSG00000099796  0.005670842                        -Inf #> ENSMUSG00000096992  0.005007492                        -Inf #> ENSMUSG00000026039  0.052527690                        -Inf #> ENSMUSG00000036480  0.021403855                        -Inf #> ENSMUSG00000034159  0.004635958                        -Inf #> ENSMUSG00000105842  0.006288954                        -Inf ordered_comp <- comp[is.finite(comp[, 2]), ] ordered_comp <- ordered_comp[order(abs(ordered_comp[, 2]), decreasing = TRUE), ] head(ordered_comp) #>                    d1t1_vs_d2t2 log2FoldChange_d1t1_vs_d2t2 #> ENSMUSG00000057465  0.002513712                    9.428071 #> ENSMUSG00000084309  0.110722810                    9.048578 #> ENSMUSG00000074115  0.002513712                    8.499044 #> ENSMUSG00000085132  0.015363477                    7.909470 #> ENSMUSG00000046623  0.017877641                   -7.396035 #> ENSMUSG00000001021  0.106683487                   -7.082396"},{"path":"/articles/my-vignette.html","id":"standard-workflow","dir":"Articles","previous_headings":"","what":"Standard Workflow","title":"normtest workflow","text":"follows vignette standard workflow using normtest package. possible input raw data, recommended use preprocess, normalized, cleaned data. start loading data. .csv file normalized gene counts, called normalized_counts.csv. Heres data looks like: Note data already cleaned ready analysis. , however, need change column “X” rownames data, remove column. use cf() function included normtest package. simple helper function set specified column (defaults column 1) rownames, remove column data. Now must build sample_info object. purpose object define groups factors sample data belongs . Now ready run analysis. two_group_rui function run functions applicable dataset, create three .csv files current directory, “t_test_results.csv”, “two_group_welch_results.csv”, “wilcox_results.csv”. Note files names overwritten time function called. Also aware main function assign three global variables, “tier1”, “tier2”, “tier3”, subsets main data object sorted according statistical criteria ourlined description. determine many rows data sorted category nrow(tier1), nrow(tier2), nrow(tier3). call main function: Depending size data, function take several minutes run. Now data ready, sorted analyzed according appropriate criteria. , next steps hands. next steps look genes significantly different specified groups. read analyzed .csv file apply cf function. identify “differentially expressed genes” (degs), ’ll write small function make work bit easier. function take one results tables, filter based set p value fold change, using absolute value. Now call function test results, x, y, z. pvalue cutoff 0.05, log2FoldChange cutoff 1. Now like, can combine degs found one data object. now identified differentially expressed genes conclude workflow.","code":"counts <- read.csv(\"normalized_counts.csv\") head(counts) #>                    X         X1        X2        X3        X4        Y1 #> 1 ENSMUSG00000051951 195.829485 144.00549 101.60121  56.53073  96.84125 #> 2 ENSMUSG00000103377   8.047787  14.83693  10.16012  29.80711  15.97381 #> 3 ENSMUSG00000102331 160.955741 236.51811 298.03022 450.19017 425.30280 #> 4 ENSMUSG00000025902  69.747488  77.67569  66.60524  83.25435  44.92635 #> 5 ENSMUSG00000033845 574.075477 483.50935 580.25581 537.55584 578.05240 #> 6 ENSMUSG00000102275  14.754276  10.47313  24.83585  29.80711  44.92635 #>          Y2        Y3        Y4 #> 1 183.56907 238.57664 125.44534 #> 2  10.46249  15.52382  27.58018 #> 3 350.01771 191.18813 344.30744 #> 4  81.79762  76.80207  73.84371 #> 5 510.75954 476.33623 549.82428 #> 6  28.53405  17.15791  15.12462 counts <- cf(counts) head(counts) #>                            X1        X2        X3        X4        Y1        Y2 #> ENSMUSG00000051951 195.829485 144.00549 101.60121  56.53073  96.84125 183.56907 #> ENSMUSG00000103377   8.047787  14.83693  10.16012  29.80711  15.97381  10.46249 #> ENSMUSG00000102331 160.955741 236.51811 298.03022 450.19017 425.30280 350.01771 #> ENSMUSG00000025902  69.747488  77.67569  66.60524  83.25435  44.92635  81.79762 #> ENSMUSG00000033845 574.075477 483.50935 580.25581 537.55584 578.05240 510.75954 #> ENSMUSG00000102275  14.754276  10.47313  24.83585  29.80711  44.92635  28.53405 #>                           Y3        Y4 #> ENSMUSG00000051951 238.57664 125.44534 #> ENSMUSG00000103377  15.52382  27.58018 #> ENSMUSG00000102331 191.18813 344.30744 #> ENSMUSG00000025902  76.80207  73.84371 #> ENSMUSG00000033845 476.33623 549.82428 #> ENSMUSG00000102275  17.15791  15.12462 sample_info <- data.frame(sample = colnames(counts), group = c(rep(\"GroupX\", 4), rep(\"GroupY\", 4))) sample_info #>   sample  group #> 1     X1 GroupX #> 2     X2 GroupX #> 3     X3 GroupX #> 4     X4 GroupX #> 5     Y1 GroupY #> 6     Y2 GroupY #> 7     Y3 GroupY #> 8     Y4 GroupY two_group_rui(counts, sample_info$group) x <- read.csv(\"t_test_results.csv\") x <- cf(x) y <- read.csv(\"two_group_welch_results.csv\") y <- cf(y) z <- read.csv(\"wilcox_results.csv\") z <- cf(z) #t_test_results head(x) #>                         Pval log2FoldChange_GroupY_vs_GroupX #> ENSMUSG00000051951 0.4303899                      -0.3719789 #> ENSMUSG00000103377 0.7931455                      -0.1458919 #> ENSMUSG00000102331 0.6182500                      -0.1942432 #> ENSMUSG00000025902 0.6049529                       0.1000254 #> ENSMUSG00000033845 0.6479577                       0.0406395 #> ENSMUSG00000102275 0.4579297                      -0.4048290 #welch_results head(y) #>                          Pval log2FoldChange_GroupY_vs_GroupX #> ENSMUSG00000033813 0.35961540                     -0.22591228 #> ENSMUSG00000033740 0.87532371                     -0.05072133 #> ENSMUSG00000051285 0.02072324                     -0.34553262 #> ENSMUSG00000061024 0.63388010                     -0.06002674 #> ENSMUSG00000025915 0.69104190                     -0.10135416 #> ENSMUSG00000103825 0.93187677                      0.02338045 #wilcox_results head(z) #>                         Pval log2FoldChange_GroupY_vs_GroupX #> ENSMUSG00000033793 0.8857143                     -0.11873657 #> ENSMUSG00000025916 0.6857143                     -0.81569199 #> ENSMUSG00000102937 0.4857143                      0.14976987 #> ENSMUSG00000104027 0.4857143                      1.16691268 #> ENSMUSG00000102386 0.8857143                     -0.05847992 #> ENSMUSG00000037509 0.2000000                      0.07975997 id_deg <- function(data, p, f) {     degs <- data[data[, 1] < p, ]     degs <- degs[abs(degs[, 2]) > f, ]     return(degs) } x_degs <- id_deg(x, 0.05, 1) y_degs <- id_deg(y, 0.05, 1) z_degs <- id_deg(z, 0.05, 1) # number of degs found from t-test nrow(x_degs) #> [1] 39 # number of degs found from welch-test nrow(y_degs) #> [1] 2 # number of degs found from wilcox-test nrow(z_degs) #> [1] 5 #well look only at x, but the others will look very similar head(x_degs) #>                          Pval log2FoldChange_GroupY_vs_GroupX #> ENSMUSG00000026196 0.03644788                       -1.260348 #> ENSMUSG00000102553 0.01321143                       -1.129470 #> ENSMUSG00000091288 0.04632879                       -1.609100 #> ENSMUSG00000083397 0.02363911                        1.027740 #> ENSMUSG00000097288 0.01144887                        1.151352 #> ENSMUSG00000044583 0.01493826                       -1.176794 degs <- rbind(x_degs, y_degs, z_degs) #number of degs found nrow(degs) #> [1] 46 head(degs) #>                          Pval log2FoldChange_GroupY_vs_GroupX #> ENSMUSG00000026196 0.03644788                       -1.260348 #> ENSMUSG00000102553 0.01321143                       -1.129470 #> ENSMUSG00000091288 0.04632879                       -1.609100 #> ENSMUSG00000083397 0.02363911                        1.027740 #> ENSMUSG00000097288 0.01144887                        1.151352 #> ENSMUSG00000044583 0.01493826                       -1.176794"},{"path":"/articles/two_group_vignette.html","id":"standard-workflow","dir":"Articles","previous_headings":"","what":"Standard Workflow","title":"normtest workflow","text":"follows vignette standard workflow using normtest package analyze data two groups. possible input raw data, recommended use preprocessed, normalized, cleaned data. start loading data. .csv file normalized gene counts, called normalized_counts.csv. Heres data looks like: Note data already cleaned ready analysis. , however, need change column “X” rownames data, remove column. use cf() function included normtest package. simple helper function set specified column (defaults column 1) rownames, remove column data. Now must build sample_info object. purpose object define groups factors sample data belongs . Now ready run analysis. two_group_rui function run functions applicable dataset, create three .csv files current directory, “t_test_results.csv”, “two_group_welch_results.csv”, “wilcox_results.csv”. Note files names overwritten time function called. Also aware main function assign three global variables, “tier1”, “tier2”, “tier3”, subsets main data object sorted according statistical criteria ourlined description. determine many rows data sorted category nrow(tier1), nrow(tier2), nrow(tier3). call main function: Depending size data, function take several minutes run. Now data ready, sorted analyzed according appropriate criteria. , next steps hands. next steps look genes significantly different specified groups. read analyzed .csv file apply cf function. identify “differentially expressed genes” (degs), ’ll write small function make work bit easier. function take one results tables, filter based set p value fold change, using absolute value. Now call function test results, x, y, z. pvalue cutoff 0.05, log2FoldChange cutoff 1. Now like, can combine degs found one data object. now identified differentially expressed genes conclude workflow.","code":"counts <- read.csv(\"twogroup_counts.csv\") head(counts) #>                    X         X1        X2        X3        X4        Y1 #> 1 ENSMUSG00000051951 195.829485 144.00549 101.60121  56.53073  96.84125 #> 2 ENSMUSG00000103377   8.047787  14.83693  10.16012  29.80711  15.97381 #> 3 ENSMUSG00000102331 160.955741 236.51811 298.03022 450.19017 425.30280 #> 4 ENSMUSG00000025902  69.747488  77.67569  66.60524  83.25435  44.92635 #> 5 ENSMUSG00000033845 574.075477 483.50935 580.25581 537.55584 578.05240 #> 6 ENSMUSG00000102275  14.754276  10.47313  24.83585  29.80711  44.92635 #>          Y2        Y3        Y4 #> 1 183.56907 238.57664 125.44534 #> 2  10.46249  15.52382  27.58018 #> 3 350.01771 191.18813 344.30744 #> 4  81.79762  76.80207  73.84371 #> 5 510.75954 476.33623 549.82428 #> 6  28.53405  17.15791  15.12462 counts <- cf(counts) head(counts) #>                            X1        X2        X3        X4        Y1        Y2 #> ENSMUSG00000051951 195.829485 144.00549 101.60121  56.53073  96.84125 183.56907 #> ENSMUSG00000103377   8.047787  14.83693  10.16012  29.80711  15.97381  10.46249 #> ENSMUSG00000102331 160.955741 236.51811 298.03022 450.19017 425.30280 350.01771 #> ENSMUSG00000025902  69.747488  77.67569  66.60524  83.25435  44.92635  81.79762 #> ENSMUSG00000033845 574.075477 483.50935 580.25581 537.55584 578.05240 510.75954 #> ENSMUSG00000102275  14.754276  10.47313  24.83585  29.80711  44.92635  28.53405 #>                           Y3        Y4 #> ENSMUSG00000051951 238.57664 125.44534 #> ENSMUSG00000103377  15.52382  27.58018 #> ENSMUSG00000102331 191.18813 344.30744 #> ENSMUSG00000025902  76.80207  73.84371 #> ENSMUSG00000033845 476.33623 549.82428 #> ENSMUSG00000102275  17.15791  15.12462 sample_info <- data.frame(sample = colnames(counts), group = c(rep(\"GroupX\", 4), rep(\"GroupY\", 4))) sample_info #>   sample  group #> 1     X1 GroupX #> 2     X2 GroupX #> 3     X3 GroupX #> 4     X4 GroupX #> 5     Y1 GroupY #> 6     Y2 GroupY #> 7     Y3 GroupY #> 8     Y4 GroupY two_group_rui(counts, sample_info$group) x <- read.csv(\"t_test_results.csv\") x <- cf(x) y <- read.csv(\"two_group_welch_results.csv\") y <- cf(y) z <- read.csv(\"wilcox_results.csv\") z <- cf(z) #t_test_results head(x) #>                         Pval log2FoldChange_GroupX_vs_GroupY #> ENSMUSG00000051951 0.4303899                      -0.3719789 #> ENSMUSG00000103377 0.7931455                      -0.1458919 #> ENSMUSG00000102331 0.6182500                      -0.1942432 #> ENSMUSG00000025902 0.6049529                       0.1000254 #> ENSMUSG00000033845 0.6479577                       0.0406395 #> ENSMUSG00000102275 0.4579297                      -0.4048290 #welch_results head(y) #>                          Pval log2FoldChange_GroupX_vs_GroupY #> ENSMUSG00000033813 0.35961540                     -0.22591228 #> ENSMUSG00000033740 0.87532371                     -0.05072133 #> ENSMUSG00000051285 0.02072324                     -0.34553262 #> ENSMUSG00000061024 0.63388010                     -0.06002674 #> ENSMUSG00000025915 0.69104190                     -0.10135416 #> ENSMUSG00000103825 0.93187677                      0.02338045 #wilcox_results head(z) #>                         Pval log2FoldChange_GroupX_vs_GroupY #> ENSMUSG00000033793 0.8857143                     -0.11873657 #> ENSMUSG00000025916 0.6857143                     -0.81569199 #> ENSMUSG00000102937 0.4857143                      0.14976987 #> ENSMUSG00000104027 0.4857143                      1.16691268 #> ENSMUSG00000102386 0.8857143                     -0.05847992 #> ENSMUSG00000037509 0.2000000                      0.07975997 id_deg <- function(data, p = 0.05, f = 1) {     degs <- data[data[, 1] < p, ]     degs <- degs[abs(degs[, 2]) > f, ]     return(degs) } x_degs <- id_deg(x) y_degs <- id_deg(y) z_degs <- id_deg(z) # number of degs found from t-test nrow(x_degs) #> [1] 39 # number of degs found from welch-test nrow(y_degs) #> [1] 2 # number of degs found from wilcox-test nrow(z_degs) #> [1] 5 #well look only at x, but the others will look very similar head(x_degs) #>                          Pval log2FoldChange_GroupX_vs_GroupY #> ENSMUSG00000026196 0.03644788                       -1.260348 #> ENSMUSG00000102553 0.01321143                       -1.129470 #> ENSMUSG00000091288 0.04632879                       -1.609100 #> ENSMUSG00000083397 0.02363911                        1.027740 #> ENSMUSG00000097288 0.01144887                        1.151352 #> ENSMUSG00000044583 0.01493826                       -1.176794 degs <- rbind(x_degs, y_degs, z_degs) #number of degs found nrow(degs) #> [1] 46 head(degs) #>                          Pval log2FoldChange_GroupX_vs_GroupY #> ENSMUSG00000026196 0.03644788                       -1.260348 #> ENSMUSG00000102553 0.01321143                       -1.129470 #> ENSMUSG00000091288 0.04632879                       -1.609100 #> ENSMUSG00000083397 0.02363911                        1.027740 #> ENSMUSG00000097288 0.01144887                        1.151352 #> ENSMUSG00000044583 0.01493826                       -1.176794"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2024). normtest: Sort Data Distribution Apply Appropriate Statistical Test High Throughput Manner. R package version 0.0.0.9000.","code":"@Manual{,   title = {normtest: Sort Data by Distribution and Apply Appropriate Statistical Test in a High Throughput Manner},   author = {First Last},   year = {2024},   note = {R package version 0.0.0.9000}, }"},{"path":"/index.html","id":"normtest","dir":"","previous_headings":"","what":"Sort Data by Distribution and Apply Appropriate Statistical Test in a High Throughput Manner","title":"Sort Data by Distribution and Apply Appropriate Statistical Test in a High Throughput Manner","text":"package developed address need robust statistical framework process RNA sequencing data.","code":""},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Sort Data by Distribution and Apply Appropriate Statistical Test in a High Throughput Manner","text":"Certain experiemental designs often suited preplanned statistical analysis take place data collected. vital, however, apply appropriate statistical techniques order ensure validity results. purpose package provide high throughput way sort data based tests appropriate, carry tests. example, consider researcher hopes perform two way anova test dataset. researcher may plug data generate statistical results, without consideration mathematical assumptions two way anova test, results erroneous. suitable two way anova, residuals data must normally distributed data must homoscedastic. normtest package equipped address assumptions sort data based tests can appropriately applied.","code":""},{"path":"/index.html","id":"details","dir":"","previous_headings":"","what":"Details","title":"Sort Data by Distribution and Apply Appropriate Statistical Test in a High Throughput Manner","text":"main functions, “rui” “two_group_rui”, pull together functions package appropriate order, functions available use individually. general process follows: row data object, linear model created based specified factors (groups, etc.). linear model, residuals tested using Shapiro Normality Test alpha = 0.05. Rows deemed criteria normally distributed residuals tested Levene’s Test assess equality variances (homoscedacity) amongst specified factors alpha = 0.05. Rows deemed criteria homoscedastic used construct new data object, “tier1”. Rows deemed heteroscedastic (non-homoscedastic) used construct data object “tier2”. Rows deemed non-normally distributed used construct data object “tier3” case multiple groups (> 2 groups): Tier1 analyzed two way anova test, reporting p value factor1, factor2, interaction factor1 factor2. Tukey multi comparison test done based factor3, assumed linear combination factors 1 2 (e.g., factor1 = , factor2 = B, factor 3 something like AB). P values reported groupwise comparison. Tier2 analyzed Welch’s t-test based factor3, p value reported test. Dunnett T3 multicomparison test done based also factor3, p value reported groupwise comparison. Tier3 analyzed Kruskal-Wallis rank sums test p value reported. followed Dunn multicomparison test p value reported groupwise comparison. case two groups: Tier1 analyzed Student’s t-test p value reported. Tier2 analyzed Welch’s t-test p value reported. Tier3 analyzed Wilcoxon/Mann-Whitney test p value reported. statisitcal tests performed, log2 fold changes calculated. Note program sort group names alphabetically calculating fold changes. fold changes reported log2FoldChange_GroupA_vs_GroupB, indicates following operation performed: log2(mean(groupA) / mean(groupB)) program order statstical groupwise comparison columns next fold change columns, write csv files specify tests performed. Also note global variables “tier1”, “tier2”, “tier3” assigned global R environment. can view choose, aware overwrite variables names environment.","code":""},{"path":"/reference/cf.html","id":null,"dir":"Reference","previous_headings":"","what":"Set rownames to a specified column and remove that column from the dataframe — cf","title":"Set rownames to a specified column and remove that column from the dataframe — cf","text":"Set rownames specified column remove column dataframe","code":""},{"path":"/reference/cf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set rownames to a specified column and remove that column from the dataframe — cf","text":"","code":"cf(dat, column_index = 1)"},{"path":"/reference/cf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set rownames to a specified column and remove that column from the dataframe — cf","text":"dat data object column_index index column want rownames, defaults 1","code":""},{"path":"/reference/check_means.html","id":null,"dir":"Reference","previous_headings":"","what":"check if two or more group means are zero — check_means","title":"check if two or more group means are zero — check_means","text":"check two group means zero","code":""},{"path":"/reference/check_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"check if two or more group means are zero — check_means","text":"","code":"check_means(my_data, var1)"},{"path":"/reference/check_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"check if two or more group means are zero — check_means","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/combine_fc_pvals.html","id":null,"dir":"Reference","previous_headings":"","what":"combine fold changes and pvals into single dataframe. takes column i from data1 and column i from data2 and puts them next to each other — combine_fc_pvals","title":"combine fold changes and pvals into single dataframe. takes column i from data1 and column i from data2 and puts them next to each other — combine_fc_pvals","text":"combine fold changes pvals single dataframe. takes column data1 column data2 puts next ","code":""},{"path":"/reference/combine_fc_pvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"combine fold changes and pvals into single dataframe. takes column i from data1 and column i from data2 and puts them next to each other — combine_fc_pvals","text":"","code":"combine_fc_pvals(data1, data2)"},{"path":"/reference/combine_fc_pvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"combine fold changes and pvals into single dataframe. takes column i from data1 and column i from data2 and puts them next to each other — combine_fc_pvals","text":"data1 data object n columns m rows data2 data object n columns m rows","code":""},{"path":"/reference/combine_fc_pvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"combine fold changes and pvals into single dataframe. takes column i from data1 and column i from data2 and puts them next to each other — combine_fc_pvals","text":"dataframe made data1 data2","code":""},{"path":"/reference/fold_change.html","id":null,"dir":"Reference","previous_headings":"","what":"The fold_change function iterates through the groups specified by var1 to calculate the log2FoldChange of mean(groupA) / mean(groupB). Note that this function will order the groups alphabetically before proceding, and a column named ","title":"The fold_change function iterates through the groups specified by var1 to calculate the log2FoldChange of mean(groupA) / mean(groupB). Note that this function will order the groups alphabetically before proceding, and a column named ","text":"fold_change function iterates groups specified var1 calculate log2FoldChange mean(groupA) / mean(groupB). Note function order groups alphabetically proceding, column named \"log2FoldChange_GroupB_vs_GroupA\" reporting log2(mean(GroupA) / mean(groupB))","code":""},{"path":"/reference/fold_change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The fold_change function iterates through the groups specified by var1 to calculate the log2FoldChange of mean(groupA) / mean(groupB). Note that this function will order the groups alphabetically before proceding, and a column named ","text":"","code":"fold_change(my_data, var1)"},{"path":"/reference/fold_change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The fold_change function iterates through the groups specified by var1 to calculate the log2FoldChange of mean(groupA) / mean(groupB). Note that this function will order the groups alphabetically before proceding, and a column named ","text":"my_data dataframe, double, list numeric entries var1 list points column names my_data factors experiment","code":""},{"path":"/reference/fold_change.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The fold_change function iterates through the groups specified by var1 to calculate the log2FoldChange of mean(groupA) / mean(groupB). Note that this function will order the groups alphabetically before proceding, and a column named ","text":"dataframe containing foldchanges groupwise comparison","code":""},{"path":"/reference/p.adjustment.methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Dunns multicomparison test from dunn.test library — p.adjustment.methods","title":"Dunns multicomparison test from dunn.test library — p.adjustment.methods","text":"Dunns multicomparison test dunn.test library","code":""},{"path":"/reference/p.adjustment.methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dunns multicomparison test from dunn.test library — p.adjustment.methods","text":"","code":"p.adjustment.methods"},{"path":"/reference/p.adjustment.methods.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dunns multicomparison test from dunn.test library — p.adjustment.methods","text":"object class character length 8.","code":""},{"path":"/reference/rui.html","id":null,"dir":"Reference","previous_headings":"","what":"This function puts together all the multigroup functions from the package in the correct order. — rui","title":"This function puts together all the multigroup functions from the package in the correct order. — rui","text":"function puts together multigroup functions package correct order.","code":""},{"path":"/reference/rui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function puts together all the multigroup functions from the package in the correct order. — rui","text":"","code":"rui(my_data, var1, var2, var3)"},{"path":"/reference/rui.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function puts together all the multigroup functions from the package in the correct order. — rui","text":"my_data data object var1 list points column names my_data factors experiment var2 list points column names my_data factors experiment var3 list points column names my_data factors experiment","code":""},{"path":"/reference/run_anova.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs a two way anova based on var1 * var2 for each row of my_data — run_anova","title":"Runs a two way anova based on var1 * var2 for each row of my_data — run_anova","text":"Runs two way anova based var1 * var2 row my_data","code":""},{"path":"/reference/run_anova.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs a two way anova based on var1 * var2 for each row of my_data — run_anova","text":"","code":"run_anova(my_data, var1, var2)"},{"path":"/reference/run_anova.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs a two way anova based on var1 * var2 for each row of my_data — run_anova","text":"my_data data object var1 list points column names my_data factors experiment var2 list points column names my_data factors experiment","code":""},{"path":"/reference/run_anova.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs a two way anova based on var1 * var2 for each row of my_data — run_anova","text":"data object containing p values var1, var2, interaction var1 * var2 row my_data, computed anova","code":""},{"path":"/reference/run_dunn.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs Dunn's multi comparison test on each row of my_data — run_dunn","title":"Runs Dunn's multi comparison test on each row of my_data — run_dunn","text":"Runs Dunn's multi comparison test row my_data","code":""},{"path":"/reference/run_dunn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs Dunn's multi comparison test on each row of my_data — run_dunn","text":"","code":"run_dunn(my_data, var1)"},{"path":"/reference/run_dunn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs Dunn's multi comparison test on each row of my_data — run_dunn","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/run_dunn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs Dunn's multi comparison test on each row of my_data — run_dunn","text":"data object pvalue groupwise comparison, specified var1, computed using altered version dunn.test","code":""},{"path":"/reference/run_dunnett.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs DunnettT3 multi comparison test on each row of my_data — run_dunnett","title":"Runs DunnettT3 multi comparison test on each row of my_data — run_dunnett","text":"Runs DunnettT3 multi comparison test row my_data","code":""},{"path":"/reference/run_dunnett.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs DunnettT3 multi comparison test on each row of my_data — run_dunnett","text":"","code":"run_dunnett(my_data, var1)"},{"path":"/reference/run_dunnett.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs DunnettT3 multi comparison test on each row of my_data — run_dunnett","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/run_dunnett.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs DunnettT3 multi comparison test on each row of my_data — run_dunnett","text":"data object containing p values groupwise comparison specified var1","code":""},{"path":"/reference/run_kruskal.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Kruskal-Wallis test on each row of my_data — run_kruskal","title":"Run Kruskal-Wallis test on each row of my_data — run_kruskal","text":"Run Kruskal-Wallis test row my_data","code":""},{"path":"/reference/run_kruskal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Kruskal-Wallis test on each row of my_data — run_kruskal","text":"","code":"run_kruskal(my_data, var1)"},{"path":"/reference/run_kruskal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Kruskal-Wallis test on each row of my_data — run_kruskal","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/run_kruskal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Kruskal-Wallis test on each row of my_data — run_kruskal","text":"data object p value row my_data, computed using kruskal.test","code":""},{"path":"/reference/run_ttest.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs an unpaired t-test on each row of my_data and reports the p value, computed by t.test — run_ttest","title":"Runs an unpaired t-test on each row of my_data and reports the p value, computed by t.test — run_ttest","text":"Runs unpaired t-test row my_data reports p value, computed t.test","code":""},{"path":"/reference/run_ttest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs an unpaired t-test on each row of my_data and reports the p value, computed by t.test — run_ttest","text":"","code":"run_ttest(my_data, var1)"},{"path":"/reference/run_ttest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs an unpaired t-test on each row of my_data and reports the p value, computed by t.test — run_ttest","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/run_tukey.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs a Tukey multicomparison test on each row of my_data based on var1 — run_tukey","title":"Runs a Tukey multicomparison test on each row of my_data based on var1 — run_tukey","text":"Runs Tukey multicomparison test row my_data based var1","code":""},{"path":"/reference/run_tukey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs a Tukey multicomparison test on each row of my_data based on var1 — run_tukey","text":"","code":"run_tukey(my_data, var1)"},{"path":"/reference/run_tukey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs a Tukey multicomparison test on each row of my_data based on var1 — run_tukey","text":"my_data data object var1 list points column names my_data factors experiment return data object containing p values groupwise comparison specified var1, computed TukeyHSD","code":""},{"path":"/reference/run_welch.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs a Welch t-test on each row of my_data — run_welch","title":"Runs a Welch t-test on each row of my_data — run_welch","text":"Runs Welch t-test row my_data","code":""},{"path":"/reference/run_welch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs a Welch t-test on each row of my_data — run_welch","text":"","code":"run_welch(my_data, var1)"},{"path":"/reference/run_welch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs a Welch t-test on each row of my_data — run_welch","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/run_welch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs a Welch t-test on each row of my_data — run_welch","text":"data object p value row my_data, computed using welch.test","code":""},{"path":"/reference/run_wilcox.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs two sided Wilcoxon Rank Sum test on each row of my_data and reports the p value, computed by wilcox.test — run_wilcox","title":"Runs two sided Wilcoxon Rank Sum test on each row of my_data and reports the p value, computed by wilcox.test — run_wilcox","text":"Runs two sided Wilcoxon Rank Sum test row my_data reports p value, computed wilcox.test","code":""},{"path":"/reference/run_wilcox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs two sided Wilcoxon Rank Sum test on each row of my_data and reports the p value, computed by wilcox.test — run_wilcox","text":"","code":"run_wilcox(my_data, var1)"},{"path":"/reference/run_wilcox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs two sided Wilcoxon Rank Sum test on each row of my_data and reports the p value, computed by wilcox.test — run_wilcox","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/test_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"For at least 3 groups. Test and sort data by distribution and variance equality — test_norm","title":"For at least 3 groups. Test and sort data by distribution and variance equality — test_norm","text":"least 3 groups. Test sort data distribution variance equality","code":""},{"path":"/reference/test_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"For at least 3 groups. Test and sort data by distribution and variance equality — test_norm","text":"","code":"test_norm(my_data, var1, var2)"},{"path":"/reference/test_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"For at least 3 groups. Test and sort data by distribution and variance equality — test_norm","text":"my_data numeric set data list, double, integer, etc. var1 column sample_info table used define column names my_data go var1 var2 column sample_info table used define column names my_data go var2","code":""},{"path":"/reference/test_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"For at least 3 groups. Test and sort data by distribution and variance equality — test_norm","text":"Three dataframes tier1, tier2, tier3 assigned global environment","code":""},{"path":"/reference/two_group_rui.html","id":null,"dir":"Reference","previous_headings":"","what":"This function puts together all the two group functions from the package in the correct order. — two_group_rui","title":"This function puts together all the two group functions from the package in the correct order. — two_group_rui","text":"function puts together two group functions package correct order.","code":""},{"path":"/reference/two_group_rui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function puts together all the two group functions from the package in the correct order. — two_group_rui","text":"","code":"two_group_rui(my_data, var1)"},{"path":"/reference/two_group_rui.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function puts together all the two group functions from the package in the correct order. — two_group_rui","text":"my_data data object var1 list points column names my_data factors experiment","code":""},{"path":"/reference/two_group_test_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"For exactly two groups. Test and sort data by distribution and equality of variances — two_group_test_norm","title":"For exactly two groups. Test and sort data by distribution and equality of variances — two_group_test_norm","text":"exactly two groups. Test sort data distribution equality variances","code":""},{"path":"/reference/two_group_test_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"For exactly two groups. Test and sort data by distribution and equality of variances — two_group_test_norm","text":"","code":"two_group_test_norm(my_data, var1)"},{"path":"/reference/two_group_test_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"For exactly two groups. Test and sort data by distribution and equality of variances — two_group_test_norm","text":"my_data data object var1 list points column names my_data factors experiment","code":""}]
